data$FSLE0[data$FSLE0==0] = NA
weeklyDF$FSLE0[weeklyDF$FSLE0==0] = NA
# Transform data to fix skew, get all predictors on a similar scale
weeklyDF$log_Chl0 = log(weeklyDF$Chl0)
weeklyDF$log_abs_FSLE0 = log(abs(weeklyDF$FSLE0))
weeklyDF$sqrt_CEddyDist0 = sqrt(weeklyDF$CEddyDist0)
weeklyDF$sqrt_AEddyDist0 = sqrt(weeklyDF$AEddyDist0)
weeklyDF$sqrt_VelAsp0 = sqrt(weeklyDF$VelAsp0)
weeklyDF$sqrt_EKE0 = sqrt(weeklyDF$EKE0)
weeklyDF$GSDist_div100 = weeklyDF$GSDist/100
# Remove incomplete observations (NAs in FSLE)
badRows = which(is.na(data),arr.ind=TRUE)[,1]
data = data[-badRows,]
badRows = unique(which(is.na(weeklyDF),arr.ind=TRUE)[,1])
weeklyDF = weeklyDF[-badRows,]
# Check which covars are correlated w presence to determine starting covar list
smoothVarList = c("AEddyDist0",
"Chl0",
"FSLE0",
"Sal0",
"Sal200",
"EKE0",
"SSH0",
"Temp0",
"Temp200",
"VelAsp0")
weekMod = gam(Pres ~ s(sqrt(AEddyDist0),bs="cs",k=5)
+ s(log(Chl0),bs="cs",k=5)
+ s(log(abs(FSLE0)),bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
+ s(Sal200,bs="cs",k=4)
+ s(sqrt(EKE0),bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5)
+ s(Temp200,bs="cs",k=5)
+ s(sqrt(VelAsp0),bs="cc",k=5),
data=weeklyDF,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
weekMod = gam(Pres ~ s(sqrt(AEddyDist0),bs="cs",k=5)
+ s(log(Chl0),bs="cs",k=5)
+ s(log(abs(FSLE0)),bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
# + s(Sal200,bs="cs",k=4)
+ s(sqrt(EKE0),bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5),
# + s(Temp200,bs="cs",k=5)
# + s(sqrt(VelAsp0),bs="cc",k=5),
data=weeklyDF,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
# TRUE
weekMod$converged
weekModCompTable = dredge(weekMod,
beta="none",
evaluate=TRUE,
trace=TRUE)
optWeekMod = get.models(weekModCompTable,subset=1)
optWeekMod = optWeekMod[[names(optWeekMod)]]
save(optWeekMod,weekModCompTable,file=paste(outDir,'/',spec,'/','WeeklyRegionalModel.Rdata',sep=""))
## GAM approach ---------------------
# Regional model
outDir = "J:/Chpt_3/GAM_Output"
save(optWeekMod,weekModCompTable,file=paste(outDir,'/',spec,'/','WeeklyRegionalModel.Rdata',sep=""))
plot.gam(optDayMod,all.terms=TRUE,rug=TRUE,pages=1,scale=0,residuals=TRUE)
plot.gam(optWeekMod,all.terms=TRUE,rug=TRUE,pages=1,scale=0,residuals=TRUE)
png(filename=paste(outDir,'/',spec,'/',spec,'_allSitesWeeklyR.png',sep=""),width=600,height=600)
plot.gam(optWeekMod,all.terms=TRUE,rug=TRUE,pages=1,scale=0,residuals=TRUE)
while (dev.cur()>1) {dev.off()}
sites = unique(data$Site)
siteDayModList = list()
pValDayList = list()
siteDayModCompList = list()
siteWeekModList = list()
pValWeekList = list()
siteWeekModCompList = list()
for (i in 1:length(sites)){
dayInd = which(!is.na(str_match(data$Site,sites[i])))
dayData = data[dayInd,]
weekInd = which(!is.na(str_match(weeklyDF$Site,sites[i])))
weekData = weeklyDF[weekInd,]
if (sum(dayData$Pres>0)>25){
# run full daily model for this site
fullSiteDayMod = gam(Pres ~ s(sqrt(AEddyDist0),bs="cs",k=5)
+ s(log(Chl0),bs="cs",k=5)
+ s(log(abs(FSLE0)),bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
+ s(sqrt(EKE0),bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5),
data=dayData,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
siteDayModCompTable = dredge(fullSiteDayMod,
beta="none",
evaluate=TRUE,
trace=TRUE)
siteDayModCompList[[sites[i]]] = siteDayModCompTable
optSiteDayMod = get.models(siteDayModCompTable,subset=1)
optSiteDayMod = optSiteDayMod[[names(optSiteDayMod)]]
siteDayPV = summary(optSiteDayMod)$s.pv
if (any(siteDayPV>=0.05)){ # Remove non-significant terms & re-run model iteratively until only signif covars remain
flag = 1
while (flag==1){
# get terms from formula as strings
thisForm = as.character(optSiteDayMod$formula)[3]
startSmooth = str_locate_all(thisForm,'s\\(')[[1]][,1]
termInd = str_locate_all(thisForm,'\\+')[[1]][,1]
termInd = c(0,termInd,str_length(thisForm)+1)
allTerms = character()
for (j in 1:length(termInd)-1){
thisTerm = str_sub(thisForm,start=termInd[j]+1,end=termInd[j+1]-1)
allTerms = c(allTerms,thisTerm)
}
# identify which terms were non-significant
badVars = allTerms[siteDayPV>=0.05]
dontNeed = which(!is.na(str_match(badVars,"1")))
if (!is_empty(dontNeed)){
badVars = badVars[-dontNeed]}
# update model
optSiteDayMod<-eval(parse(text=paste("update(optSiteDayMod, . ~ . - ", paste(badVars,collapse="-"), ")", sep="")))
siteDayPV = summary(optSiteDayMod)$s.pv
if (!any(siteDayPV>=0.05)){
siteDayModList[[sites[i]]] = optSiteDayMod
pValDayList[[sites[i]]] = siteDayPV
flag=0
}
}
} else {
siteDayModList[[sites[i]]] = optSiteDayMod
pValDayList[[sites[i]]] = siteDayPV
}
sink(paste(outDir,'/',spec,'/',spec,'_',sites[i],'_DailySummary.txt',sep=""))
print(summary(siteDayModList[[sites[i]]]))
sink()
png(filename=paste(outDir,'/',spec,'/',spec,'_',sites[i],'_DailyR.png',sep=""),width=600,height=600)
plot.gam(siteDayModList[[sites[i]]],all.terms=TRUE,rug=TRUE,pages=1,main=sites[i],scale=0,residuals=TRUE)
while (dev.cur()>1) {dev.off()}
}
if (sum(weekData$Pres>0)>25){
#run full weekly model for this site
fullSiteWeekMod = gam(Pres ~ s(sqrt(AEddyDist0),bs="cs",k=5)
+ s(log(Chl0),bs="cs",k=5)
+ s(log(abs(FSLE0)),bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
+ s(sqrt(EKE0),bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5),
data=weekData,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
siteWeekModCompTable = dredge(fullSiteWeekMod,
beta="none",
evaluate=TRUE,
trace=TRUE)
siteWeekModCompList[[sites[i]]] = siteWeekModCompTable
optSiteWeekMod = get.models(siteWeekModCompTable,subset=1)
optSiteWeekMod = optSiteWeekMod[[names(optSiteWeekMod)]]
siteWeekPV = summary(optSiteWeekMod)$s.pv
if (any(siteWeekPV>=0.05)){ # Remove non-significant terms & re-run model iteratively until only signif covars remain
flag = 1
while (flag==1){
# get terms from formula as strings
thisForm = as.character(optSiteWeekMod$formula)[3]
startSmooth = str_locate_all(thisForm,'s\\(')[[1]][,1]
termInd = str_locate_all(thisForm,'\\+')[[1]][,1]
termInd = c(0,termInd,str_length(thisForm)+1)
allTerms = character()
for (j in 1:length(termInd)-1){
thisTerm = str_sub(thisForm,start=termInd[j]+1,end=termInd[j+1]-1)
allTerms = c(allTerms,thisTerm)
}
# identify which terms were non-significant
badVars = allTerms[siteWeekPV>=0.05]
dontNeed = which(!is.na(str_match(badVars,"1")))
if (!is_empty(dontNeed)){
badVars = badVars[-dontNeed]}
# update model
optSiteWeekMod<-eval(parse(text=paste("update(optSiteWeekMod, . ~ . - ", paste(badVars,collapse="-"), ")", sep="")))
siteWeekPV = summary(optSiteWeekMod)$s.pv
if (!any(siteWeekPV>=0.05)){
siteWeekModList[[sites[i]]] = optSiteWeekMod
pValWeekList[[sites[i]]] = siteWeekPV
flag=0
}
}
} else {
siteWeekModList[[sites[i]]] = optSiteWeekMod
pValWeekList[[sites[i]]] = siteWeekPV
}
sink(paste(outDir,'/',spec,'/',spec,'_',sites[i],'_WeeklySummary.txt',sep=""))
print(summary(siteWeekModList[[sites[i]]]))
sink()
png(filename=paste(outDir,'/',spec,'/',spec,'_',sites[i],'_WeeklyR.png',sep=""),width=600,height=600)
plot.gam(siteWeekModList[[sites[i]]],all.terms=TRUE,rug=TRUE,pages=1,main=sites[i],scale=0,residuals=TRUE)
while (dev.cur()>1) {dev.off()}
}
}
outDir = "J:/Chpt_3/GEEGLM_Output"
# Check which covars are correlated w presence to determine starting covar list
smoothVarList = c("sqrt_AEddyDist0",
"log_Chl0",
"log_abs_FSLE0",
"Sal0",
"Sal200",
"sqrt_EKE0",
"SSH0",
"Temp0",
"Temp200",
"sqrt_VelAsp0")
# Make smooth terms, run full model and check collinearity
smoothVarList = c("log_Chl0",
"log_abs_FSLE0",
"Sal0",
"Sal200",
"sqrt_EKE0",
"SSH0",
"Temp0",
"Temp200",
"sqrt_VelAsp0")
knotList = list(c(0.333,0.666),
c(0.5),
c(0.333,0.666),
c(0.333,0.666),
c(0.275,0.5,0.725),
c(0.333,0.666),
c(0.5),
c(0.275,0.5,0.725),
c(0.333,0.666)) # velocity aspect has to have at least 4 knots to be circular
linVarList = list("sqrt_AEddyDist0")
smoothNameList = character()
for (i in 1:length(smoothVarList)){
if (str_detect(smoothVarList[i],"Asp")){ periodic=TRUE} else {periodic=FALSE}
eval(parse(text=paste('S_',smoothVarList[i],'= mSpline(weeklyDF$',smoothVarList[i],',knots=quantile(weeklyDF$',smoothVarList[i],',probs=unlist(knotList[i])),Boundary.knots=c(min(weeklyDF$',smoothVarList[i],'),max(weeklyDF$',smoothVarList[i],')),periodic=periodic)',sep="")))
smoothNameList = c(smoothNameList,paste('S_',smoothVarList[i],sep=""))
}
thisForm = formula(paste('Pres~',paste(c(smoothNameList,linVarList),collapse="+"),sep=""))
fullMod = geeglm(thisForm,
family=poisson,
data=weeklyDF,
id=GroupID,
corstr="ar1",
na.action="na.fail")
# determine block size based on autocorrelation
sites = unique(weeklyDF$Site)
siteCorr = data.frame(Site=character(length=length(sites)),Corr=numeric(length=length(sites)))
for (i in 1:length(sites)){
siteInd = which(weeklyDF$Site==sites[i])
BlockMod = glm(Pres~bs(Temp0)
+ bs(Sal0)
+ bs(log_Chl0)
+ bs(log_abs_FSLE0)
+ bs(VelMag0)
+ bs(sqrt_VelAsp0)
+ bs(sqrt_EKE0)
+ bs(SSH0)
+ bs(sqrt_AEddyDist0)
+ bs(sqrt_CEddyDist0)
+ bs(GSDist_div100),
data=weeklyDF[siteInd,],family=poisson)
acorr = acf(residuals(BlockMod), lag.max = 100, main=paste(spec,"at",sites[i]))
CI = ggfortify:::confint.acf(acorr)
ACFidx = which(acorr[["acf"]] < CI, arr.ind=TRUE)
siteCorr$Site[i] = sites[i]
siteCorr$Corr[i] = ACFidx[1]
}
# Create grouping variable
lagID = max(siteCorr$Corr)
numClust = length(weeklyDF$Pres)/(lagID-1)
if (numClust<length(weeklyDF$Pres)){
clustID = rep(1:ceiling(numClust),each=lagID)
clustID = clustID[1:length(weeklyDF$Pres)]
} else {
clustID = 1:length(weeklyDF$Pres)
}
weeklyDF$GroupID = clustID
fullMod = geeglm(thisForm,
family=poisson,
data=weeklyDF,
id=GroupID,
corstr="ar1",
na.action="na.fail")
# removing Sal0
fullMod = update(fullMod,. ~ . - S_Sal0)
# removing VelAsp0
fullMod = update(fullMod,. ~ . - S_sqrt_VelAsp0)
# removing Temp200
fullMod = update(fullMod,. ~ . - S_Temp200)
# dredge model
GEECompTable = dredge(fullMod,
beta="none",
evaluate=TRUE,
trace=TRUE)
# get optimal model
optMod = get.models(GEECompTable,subset=1)
optMod = optMod[[names(optMod)]]
save(optMod,GEECompTable,file=paste(outDir,'/',spec,'/','WeeklyRegionalModel.Rdata',sep=""))
# Plot terms from regional model
source("plotSmooths.R")
source("plotLinears.R")
terms = names(optMod$model)[2:length(names(optMod$model))]
plotList = list()
resids=TRUE
for (i in 1:length(terms)){
if (str_detect(terms[i],"S_")){ # plot smooth terms
term = str_remove(terms[i],"S_")
knotInd = which(!is.na(str_match(smoothVarList,term)))
k=length(unlist(knotList[knotInd]))
coefInd = which(str_detect(names(optMod$coefficients),term))
if (str_detect(term,"Asp")){periodic=TRUE} else {periodic=FALSE}
plotList[[term]] = print(plotSmooths(optMod,weeklyDF,term,coefInd,k,periodic,resids,site=NA,title=NULL))
} else { # plot linear terms
term=terms[i]
coefInd = which(str_detect(names(optMod$coefficients),term))
plotList[[term]] = print(plotLinears(optMod,weeklyDF,term,coefInd,resids,site=NA,title=NULL))
}
}
grid.arrange(grobs=plotList,nrow=3)
png(file=paste(outDir,'/',spec,'/',spec,'_allSitesWeeklyRlog10.png',sep=""),width=800,height=700,)
grid.arrange(grobs=plotList,nrow=3)
while (dev.cur()>1) {dev.off()}
load('J:/Chpt_3/GAM_Output/SBCD/WeeklyRegionalModel.Rdata')
summary(optWeekMod)
library(tidyverse)
library(mgcv.helper)
library(splines2)
library(mgcv)
library(MuMIn)
library(gratia)
library(forecast)
library(nlme)
library(itsadug)
spec = 'SBCD'
data = data.frame(read.csv('J:/Chpt_3/ModelData/UD28_masterDF.csv'))
# Round presence to get Poisson dist
data$Pres = round(data$Pres)
# create weekly time series to reduce autocorrelation
stDt = as.Date("2016-05-01")
edDt = as.Date("2019-04-30")
sites = c('HZ','OC','NC','BC','WC','NFC','HAT','GS','BP','BS')
allDates = stDt:edDt
weekDates = seq.Date(stDt,edDt,by=7)
weeklyDF = as.numeric()
for (l in 1:length(sites)) {
# Create dataframe to hold data (or NAs) for all dates
fullDatesDF = data.frame(matrix(nrow=length(allDates), ncol=44))
fullDatesDF[,1] = allDates
# sort the observations we have for this site into the full date range
thisSite = which(!is.na(str_match(data$Site,sites[l])))
matchRow = match(data$Date[thisSite],allDates)
fullDatesDF[matchRow,2:dim(data)[2]] = data[thisSite,2:dim(data)[2]]
colnames(fullDatesDF) = colnames(data)
# create grouping variable
weekID = rep(1:length(weekDates),each=7)
weekID = weekID[1:dim(fullDatesDF)[1]]
fullDatesDF$WeekID = weekID
summaryData = fullDatesDF %>%
group_by(WeekID) %>%
summarize(Pres=sum(Pres,na.rm=TRUE))
summaryData$Site = sites[l]
summaryData$WeekDate = weekDates
for (j in 4:(dim(data)[2])){
var = names(data)[j]
# calculate weekly average for this covar
eval(parse(text=paste('thisCovar=fullDatesDF%>%group_by(WeekID)%>%summarize(',var,'=mean(',var,',na.rm=TRUE))',sep="")))
eval(parse(text='summaryData[[var]]=unlist(thisCovar[,2])'))
}
weeklyDF = rbind(weeklyDF,summaryData)
}
# Remove zeros in FSLE data to prepare for later transformation
data$FSLE0[data$FSLE0==0] = NA
weeklyDF$FSLE0[weeklyDF$FSLE0==0] = NA
# Transform data to fix skew, get all predictors on a similar scale
weeklyDF$log_Chl0 = log10(weeklyDF$Chl0)
weeklyDF$log_abs_FSLE0 = log10(abs(weeklyDF$FSLE0))
weeklyDF$sqrt_CEddyDist0 = sqrt(weeklyDF$CEddyDist0)
weeklyDF$sqrt_AEddyDist0 = sqrt(weeklyDF$AEddyDist0)
weeklyDF$sqrt_VelAsp0 = sqrt(weeklyDF$VelAsp0)
weeklyDF$sqrt_EKE0 = sqrt(weeklyDF$EKE0)
weeklyDF$GSDist_div100 = weeklyDF$GSDist/100
# Remove incomplete observations (NAs in FSLE)
badRows = which(is.na(data),arr.ind=TRUE)[,1]
data = data[-badRows,]
badRows = unique(which(is.na(weeklyDF),arr.ind=TRUE)[,1])
weeklyDF = weeklyDF[-badRows,]
## GAM approach ---------------------
# Regional model
outDir = "J:/Chpt_3/GAM_Output"
# Check which covars are correlated w presence to determine starting covar list
smoothVarList = c("AEddyDist0",
"Chl0",
"FSLE0",
"Sal0",
"Sal200",
"EKE0",
"SSH0",
"Temp0",
"Temp200",
"VelAsp0")
modOpts = c("linMod","threeKnots","fourKnots","fiveKnots")
AIC_votes = matrix(nrow=length(smoothVarList),ncol=5)
for (i in 1:(length(smoothVarList))){
if (str_detect(smoothVarList[i],"Asp")){
bs = "cc"
} else { bs = "cs"}
modelCall = paste('gam(Pres~data$',smoothVarList[i],',data=data,family=poisson)',sep="")
linMod = eval(parse(text=modelCall))
modelCall = paste('gam(Pres~s(data$',smoothVarList[i],',bs="',bs,'",k=3),data=data,family=poisson)',sep="")
smoothMod1 = eval(parse(text=modelCall))
modelCall = paste('gam(Pres~s(data$',smoothVarList[i],',bs="',bs,'",k=4),data=data,family=poisson)',sep="")
smoothMod2 = eval(parse(text=modelCall))
modelCall = paste('gam(Pres~s(data$',smoothVarList[i],',bs="',bs,'",k=5),data=data,family=poisson)',sep="")
smoothMod3 = eval(parse(text=modelCall))
AIC_votes[i,1:4] = c(AIC(linMod)[[1]],AIC(smoothMod1)[[1]],AIC(smoothMod2)[[1]],AIC(smoothMod3)[[1]])
AIC_votes[i,5] = modOpts[which.min(AIC_votes[i,1:4])]
}
colnames(AIC_votes) = c(modOpts,"Best")
rownames(AIC_votes) = smoothVarList[]
AIC_votes
weekMod = gam(Pres ~ s(sqrt_AEddyDist0,bs="cs",k=5)
+ s(log_Chl0,bs="cs",k=5)
+ s(log_abs_FSLE0,bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
+ s(Sal200,bs="cs",k=4)
+ s(sqrt_EKE0,bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5)
+ s(Temp200,bs="cs",k=5)
+ s(sqrt_VelAsp0,bs="cc",k=5),
data=weeklyDF,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
# TRUE
weekMod$converged
conCurv = concurvity(weekMod,full=FALSE)
round(conCurv$estimate,digits=4)
round(conCurv$estimate,digits=4)
weekMod = gam(Pres ~ s(sqrt(AEddyDist0),bs="cs",k=5)
+ s(log(Chl0),bs="cs",k=5)
+ s(log(abs(FSLE0)),bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
# + s(Sal200,bs="cs",k=4)
+ s(sqrt(EKE0),bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5),
# + s(Temp200,bs="cs",k=5)
# + s(sqrt(VelAsp0),bs="cc",k=5),
data=weeklyDF,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
weekMod = gam(Pres ~ s(sqrt_AEddyDist0,bs="cs",k=5)
+ s(log_Chl0,bs="cs",k=5)
+ s(log_abs_FSLE0,bs="cs",k=5)
+ s(Sal0,bs="cs",k=4)
# + s(Sal200,bs="cs",k=4)
+ s(sqrt_EKE0,bs="cs",k=5)
+ s(SSH0,bs="cs",k=5)
+ s(Temp0,bs="cs",k=5),
# + s(Temp200,bs="cs",k=5)
# + s(sqrt_VelAsp0,bs="cc",k=5),
data=weeklyDF,
family=poisson,
method="REML",
select=TRUE,
gamma=1.4,
na.action="na.fail")
# TRUE
weekMod$converged
# check concurvity of smooth terms
conCurv = concurvity(weekMod,full=FALSE)
round(conCurv$estimate,digits=4)
weekModCompTable = dredge(weekMod,
beta="none",
evaluate=TRUE,
trace=TRUE)
# run optimal models
# optDayMod = get.models(dayModCompTable,subset=1)
# optDayMod = optDayMod[[names(optDayMod)]]
# save(optDayMod,dayModCompTable,file=paste(outDir,'/',spec,'/','DailyRegionalModel.Rdata',sep=""))
optWeekMod = get.models(weekModCompTable,subset=1)
optWeekMod = optWeekMod[[names(optWeekMod)]]
save(optWeekMod,weekModCompTable,file=paste(outDir,'/',spec,'/','WeeklyRegionalModel.Rdata',sep=""))
summary(optWeekMod)
# plot
# png(filename=paste(outDir,'/',spec,'/',spec,'_allSitesDaily.png',sep=""),width=600,height=600)
# plot.gam(optDayMod,all.terms=TRUE,rug=TRUE,pages=1,scale=0,residuals=TRUE)
# while (dev.cur()>1) {dev.off()}
png(filename=paste(outDir,'/',spec,'/',spec,'_allSitesWeekly.png',sep=""),width=600,height=600)
plot.gam(optWeekMod,all.terms=TRUE,rug=TRUE,pages=1,scale=0,residuals=FALSE)
while (dev.cur()>1) {dev.off()}
10^(-1)
10^(-2.5)
source("D:/Code/Temporal_Analyses/plot_dolphinJDsmooths.R", echo=TRUE)
